{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from pymatgen.core import Composition\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_material(formula, label, space_grp='Unknown'):\n",
    "    comp = Composition(formula)\n",
    "    comp_d = comp.get_el_amt_dict()\n",
    "    comp_l = list(comp_d.keys())   \n",
    "    comp_l.sort()   # Arranges alphabetically\n",
    "    arranged_formula = ''\n",
    "    for i in comp_l:\n",
    "        arranged_formula += i\n",
    "        arranged_formula += str(int(comp_d[i]))\n",
    "    \n",
    "    return (space_grp, arranged_formula, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making semimetals file\n",
    "# O5P1V2 is V2OPO4\n",
    "sm_str = '''As1Ta1,109\n",
    "P1Ta1,109\n",
    "As1Nb1,109\n",
    "Nb1P1,109\n",
    "Al1Mn1Ti2\n",
    "Mn3Sn1\n",
    "S4V3\n",
    "Ir1Ta1Te4\n",
    "Te2W1\n",
    "P2W1\n",
    "Mo1P2\n",
    "Co3S2Sn2\n",
    "Ir2O7Y2\n",
    "Cr2Hg1Se4\n",
    "Al1Ce1Ge1\n",
    "Fe3Sn2\n",
    "Nb2O7Sn2\n",
    "Co1Ga1Mn2\n",
    "Bi1Ga1\n",
    "In1Bi1\n",
    "Al1Ce1Si1\n",
    "Ta3S2\n",
    "Al1Ge1La1\n",
    "Al1La1Si1\n",
    "Al1Ce1Ge1\n",
    "Al1Ge1Pr1\n",
    "O5P1V2\n",
    "Al1Gd1Si1\n",
    "Gd1Si1\n",
    "Bi1Gd1Pt1\n",
    "Co2Ga1Mn1\n",
    "Al1Co2Mn1\n",
    "Co2Mn1Si1\n",
    "Co2Ge1Mn1\n",
    "Co2Mn1Sn1\n",
    "Ni3S3,160\n",
    "Ni3Se3,160\n",
    "In1Mn1Ti2\n",
    "Ir1Ta1Te4\n",
    "Gd1Te1Sb1\n",
    "Ga1Ge1Li1\n",
    "Ga1Li1Se1\n",
    "Al2Ca1Si2\n",
    "As1Cu1Mn1\n",
    "As2Cd2Eu1\n",
    "Al1Ge1La1,109\n",
    "Al22Mo5,43\n",
    "As1Pd5,5\n",
    "Au1Ca1Sn1,44\n",
    "Au2Ga1,36\n",
    "B1La1Pt2,180\n",
    "Ba1Ge3Pt1,107\n",
    "Ba1Pd1Si3,107\n",
    "Ba1Pd1Sn3,107\n",
    "Ba1Pt1Si3,107\n",
    "Ba1Pt1Sn3,107\n",
    "Bi1Pb1Pd2,36\n",
    "Bi1Pd1,4\n",
    "Bi2Pt1,157\n",
    "Bi3Pd8,146\n",
    "Ca1Ge2Pt2,4 \n",
    "Ca1Pt1Si3,107 \n",
    "Ca2Ge1Pd2,43 \n",
    "Ca3Cd2,102\n",
    "Ge1Pd5,5 \n",
    "Ge2Nb1,180\n",
    "Ge3Pd1Sr1,107\n",
    "Ge3Pt1Sr1,107\n",
    "Ge4Zr5,92\n",
    "Hf5Si4,92\n",
    "Hg1Pd1,198\n",
    "In1Sr1,43\n",
    "La5Si4,92\n",
    "Mg1Pt1,198\n",
    "Nb1Re1Si1,46\n",
    "O1Ti3,149\n",
    "Pb3Pd5,5\n",
    "Pd1Sn3Sr1,107\n",
    "Pd2Sb1,36\n",
    "Pd8Sb3,146\n",
    "Pd8Sb3,161\n",
    "Re1Si1Ta1,46\n",
    "Re2Sc1Si3,38\n",
    "Re2Sc3Si3,5\n",
    "Re8Sc5Si12,38\n",
    "Sc9Te2,6 \n",
    "Si1Ti1,25\n",
    "Si4Zr5,92\n",
    "Ta21Te13,183\n",
    "Bi1Pd1,36\n",
    "Al2C1Mo3,213\n",
    "Ge6La4Mg5,36\n",
    "Ge6Y4Zn5,36\n",
    "Mo1Pt2Si3,26\n",
    "O1Ti6,159\n",
    "Pd5Sb2,185 \n",
    "Al2Y3,102'''\n",
    "\n",
    "all_materials = set()\n",
    "sm_list = []\n",
    "for i in sm_str.split():\n",
    "    try:\n",
    "        _ = i.split(',')\n",
    "        j = format_material(_[0], 1, _[1])\n",
    "        sm_list.append(j)\n",
    "        all_materials.add(j[1])\n",
    "    except:\n",
    "        j = format_material(i, 1)\n",
    "        sm_list.append(j)\n",
    "        all_materials.add(j[1])\n",
    "\n",
    "# Saving Semimetals in a file\n",
    "with open('raw_data\\\\semimetals.csv', 'w', newline='') as f:\n",
    "    w = csv.writer(f)\n",
    "    for i in sm_list:\n",
    "        w.writerow(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data from topogivity text files\n",
    "files_txt = ['raw_data\\\\case1_ccmp.txt', 'raw_data\\\\case3_ccmp.txt', 'raw_data\\\\tci_ccmp.txt', 'raw_data\\\\ti_ccmp.txt']\n",
    "txt_materials = []\n",
    "\n",
    "for i in files_txt:\n",
    "    with open(i, 'r') as f:\n",
    "        mat = f.readlines()\n",
    "        for j in mat:\n",
    "            _ = j.strip().split(',')\n",
    "            if 'case1' in i:\n",
    "                __ = format_material(_[1].strip(), 0, _[0].strip())\n",
    "                txt_materials.append(__)\n",
    "                all_materials.add(__[1])\n",
    "            else:\n",
    "                __ = format_material(_[1].strip(), 1, _[0].strip())\n",
    "                txt_materials.append(__)\n",
    "                all_materials.add(__[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data from CSV files\n",
    "txt_csv = []\n",
    "\n",
    "with open('raw_data\\\\Dataset Materials Cloud.csv', 'r') as f:\n",
    "    w = csv.reader(f)\n",
    "    for j in w:\n",
    "        _ = format_material(j[0], j[1], j[7])\n",
    "        if _[1] not in all_materials:\n",
    "            txt_csv.append(_)\n",
    "            all_materials.add(_[1])\n",
    "\n",
    "with open('raw_data\\\\All_TQC.csv', 'r') as f:\n",
    "    w = csv.reader(f)\n",
    "    for j in w:\n",
    "        _ = format_material(j[0], 0)\n",
    "        if _[1] not in all_materials:\n",
    "            txt_csv.append(_)\n",
    "            all_materials.add(_[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making final dataset\n",
    "final_materials = set(sm_list + txt_materials + txt_csv)\n",
    "final_materials = list(final_materials)\n",
    "shuffle(final_materials)\n",
    "\n",
    "with open('processed_data.csv', 'w', newline='') as f:\n",
    "    w = csv.writer(f)\n",
    "    for i in final_materials:\n",
    "        w.writerow(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making processed data from only Topogivity files\n",
    "files_txt = ['raw_data\\\\case1_ccmp.txt', 'raw_data\\\\case3_ccmp.txt', 'raw_data\\\\tci_ccmp.txt', 'raw_data\\\\ti_ccmp.txt']\n",
    "txt_materials = []\n",
    "\n",
    "for i in files_txt:\n",
    "    with open(i, 'r') as f:\n",
    "        mat = f.readlines()\n",
    "        for j in mat:\n",
    "            _ = j.strip().split(',')\n",
    "            if 'case1' in i:\n",
    "                __ = format_material(_[1].strip(), 0, _[0].strip())\n",
    "                txt_materials.append(__)\n",
    "            else:\n",
    "                __ = format_material(_[1].strip(), 1, _[0].strip())\n",
    "                txt_materials.append(__)\n",
    "\n",
    "shuffle(txt_materials)\n",
    "\n",
    "with open('topogivity_processed_data.csv', 'w', newline='') as f:\n",
    "    w = csv.writer(f)\n",
    "    for i in txt_materials:\n",
    "        w.writerow(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting Datasets into Training & Discovery Space\n",
    "discovery_space_groups = {1, 3, 4, 5, 6, 7, 8, 9, 16, 17, 18, \n",
    "    19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, \n",
    "    30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, \n",
    "    41, 42, 43, 44, 45, 46, 75, 76, 77, 78, 79, \n",
    "    80, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n",
    "    99, 100, 101, 102, 103, 104, 105, 106, 107, \n",
    "    108, 109, 110, 143, 144, 145, 146, 149, 150, \n",
    "    151, 152, 153, 154, 155, 156, 157, 158, 159, \n",
    "    160, 161, 168, 169, 170, 171, 172, 173, 177, \n",
    "    178, 179, 180, 181, 182, 183, 184, 185, 186, \n",
    "    195, 196, 197, 198, 199, 207, 208, 209, 210, \n",
    "    211, 212, 213, 214}\n",
    "\n",
    "discovery_space_materials = []\n",
    "training_space_materials = []\n",
    "\n",
    "with open('processed_data.csv', 'r') as fr:\n",
    "    r = csv.reader(fr)\n",
    "    for i in r:\n",
    "        if i[0] == 'Unknown':\n",
    "            training_space_materials.append(i)\n",
    "        elif int(i[0]) in discovery_space_groups:\n",
    "            discovery_space_materials.append(i)\n",
    "        else:\n",
    "            training_space_materials.append(i)\n",
    "\n",
    "with open('space_datasets\\\\discovery_space.csv', 'w', newline='') as fw:\n",
    "    w = csv.writer(fw)\n",
    "    for i in discovery_space_materials:\n",
    "        w.writerow(i)\n",
    "\n",
    "with open('space_datasets\\\\training_space.csv', 'w', newline='') as fw:\n",
    "    w = csv.writer(fw)\n",
    "    for i in training_space_materials:\n",
    "        w.writerow(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
